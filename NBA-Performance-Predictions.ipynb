{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xCY3U2b24ts9",
        "uu4Mqdrwk6Ps",
        "YarY--AcJ9UH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXjLhxYrKUaZ",
        "colab_type": "text"
      },
      "source": [
        "# **NBA Players Individual Pefromance Predictions Using LSTM**\n",
        "\n",
        "This notebok shows the process of building training and experimenting with a Long Short Term Memory neural network (LSTM), designed for predicting NBA players Performances thorughout a series of games.\n",
        "\n",
        "**The Motivation:** We're 3 basketball enphusiasts who share a passion for the NBA and take part in Fantasy NBA leagues. Fantasy games are all about trying to predict players performances and build a winning team based on these perdictions. Of course online Fantasy games are just one way in which these predictions might come in handy! Basketball professionals such as scouters managers and coaches might find this tool extremely helpful.\n",
        "\n",
        "**The Main idea:** Building a network which recieves as input a sequence of N successive game statistics vectors ( [Points, Rebounds, Steals, etc...] ) played by an NBA player, and for each game tries to predict what is the range of the PER (Player Efficiency Rating) score that the player got in the next game.\n",
        "By trying to predict a range of scores rather than a specific number, we casted this regression problem of as a classification one. We hope this will make our network easier to evaluate and experiment with.\n",
        "\n",
        "**The logic** behind looking at a sequence of games in order to predict the scores, rather than making a perdiction based on a single game - which is what a simple Feed Forward network would try to accomplish - is simple:\n",
        "We assume that a player's PER scores in successive games are co-dependent as a player might be in certain shape and therefore achive similar results in those games. This is why using LSTM which is a type of Recurrent Neural Network (RNN) might be well suited to learn these dependencies.\n",
        "\n",
        "We'll try to confirm this **hypothesis** by building a simple Feed Forward network as well and comparing the Results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCY3U2b24ts9",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset Building**\n",
        "\n",
        "We couldn't find a proper dataset containing individual players performance history, so we decided to build one on our own.\n",
        "We used an open source project - [basketball-reference-scraper](https://pypi.org/project/basketball-reference-scraper/)  - for scraping NBA stats out of [https://www.basketball-reference.com/](https://www.basketball-reference.com/) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p3yGWd2VMvO",
        "colab_type": "text"
      },
      "source": [
        "**Scraping Raw Data**\n",
        "\n",
        "Scraping NBA players individual performances (box-scores) data between 2000-2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaN5oZbotJKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNJkxJLVt0vS",
        "colab_type": "code",
        "outputId": "d7872558-d525-4ce6-993d-1c64ba311d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDP0dRbl6m5v",
        "colab_type": "code",
        "outputId": "0d22f797-5b0d-47e9-ee94-5fa18a175429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install basketball-reference-scraper"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting basketball-reference-scraper\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/e0/a38834f37ab9a28781b45086120c6187681a69389e3211cdd4d2d82422f4/basketball_reference_scraper-1.0.7-py3-none-any.whl\n",
            "Collecting six==1.13.0\n",
            "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.6/dist-packages (from basketball-reference-scraper) (2.8.1)\n",
            "Collecting pytz==2019.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 38.5MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 160kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.6/dist-packages (from basketball-reference-scraper) (0.25.3)\n",
            "Requirement already satisfied: bs4==0.0.1 in /usr/local/lib/python3.6/dist-packages (from basketball-reference-scraper) (0.0.1)\n",
            "Collecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 11.1MB/s \n",
            "\u001b[?25hCollecting lxml==4.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/30/affd16b77edf9537f5be051905f33527021e20d563d013e8c42c7fd01949/lxml-4.4.2-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8MB 23.3MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/a1/c698cf319e9cfed6b17376281bd0efc6bfc8465698f54170ef60a485ab5d/beautifulsoup4-4.8.2-py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 62.9MB/s \n",
            "\u001b[?25hCollecting soupsieve==1.9.5\n",
            "  Downloading https://files.pythonhosted.org/packages/81/94/03c0f04471fc245d08d0a99f7946ac228ca98da4fa75796c507f61e688c2/soupsieve-1.9.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->basketball-reference-scraper) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->basketball-reference-scraper) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->basketball-reference-scraper) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->basketball-reference-scraper) (3.0.4)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, pytz, numpy, requests, lxml, soupsieve, beautifulsoup4, basketball-reference-scraper\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: numpy 1.18.2\n",
            "    Uninstalling numpy-1.18.2:\n",
            "      Successfully uninstalled numpy-1.18.2\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed basketball-reference-scraper-1.0.7 beautifulsoup4-4.8.2 lxml-4.4.2 numpy-1.18.1 pytz-2019.3 requests-2.22.0 six-1.13.0 soupsieve-1.9.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pytz",
                  "requests",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03nj3GZf7iJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import basketball_reference_scraper as bc\n",
        "from basketball_reference_scraper.teams import get_roster\n",
        "from basketball_reference_scraper.players import get_game_logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdMvmyh9p_oJ",
        "colab_type": "code",
        "outputId": "e734e4be-a4fd-4717-ca75-6efe4630b1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Create Team <-> Index dictionary\n",
        "teams = ['ATL','SLH','MIL','TCB','BOS','BRK','NJN','CHI','CHO','CHA','CLE','DAL','DEN','DET','FWP','GSW','SFW','CHH',\n",
        "'PHI','HOU','IND','LAC','SDC','BUF','LAL','MIN','MEM','VAN','MIA','MIL','MIN','NOP','NOK','NOH','NYK','OKC','SEA','ORL','PHI','SYR','PHO',\n",
        "'POR','SAC','KCK','KCK','CIN','ROR','SAS','TOR','UTA','NOJ','WAS','WAS','CAP','BAL','CHI','CHI','AND','CHI','IND','SRS','SLB','WAS','WAT']\n",
        "\n",
        "team2idx = {t:i for i,t in enumerate(teams)}\n",
        "idx2team = {i:t for t,i in team2idx.items()}\n",
        "print(team2idx)\n",
        "print(idx2team)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ATL': 0, 'SLH': 1, 'MIL': 29, 'TCB': 3, 'BOS': 4, 'BRK': 5, 'NJN': 6, 'CHI': 58, 'CHO': 8, 'CHA': 9, 'CLE': 10, 'DAL': 11, 'DEN': 12, 'DET': 13, 'FWP': 14, 'GSW': 15, 'SFW': 16, 'CHH': 17, 'PHI': 38, 'HOU': 19, 'IND': 59, 'LAC': 21, 'SDC': 22, 'BUF': 23, 'LAL': 24, 'MIN': 30, 'MEM': 26, 'VAN': 27, 'MIA': 28, 'NOP': 31, 'NOK': 32, 'NOH': 33, 'NYK': 34, 'OKC': 35, 'SEA': 36, 'ORL': 37, 'SYR': 39, 'PHO': 40, 'POR': 41, 'SAC': 42, 'KCK': 44, 'CIN': 45, 'ROR': 46, 'SAS': 47, 'TOR': 48, 'UTA': 49, 'NOJ': 50, 'WAS': 62, 'CAP': 53, 'BAL': 54, 'AND': 57, 'SRS': 60, 'SLB': 61, 'WAT': 63}\n",
            "{0: 'ATL', 1: 'SLH', 29: 'MIL', 3: 'TCB', 4: 'BOS', 5: 'BRK', 6: 'NJN', 58: 'CHI', 8: 'CHO', 9: 'CHA', 10: 'CLE', 11: 'DAL', 12: 'DEN', 13: 'DET', 14: 'FWP', 15: 'GSW', 16: 'SFW', 17: 'CHH', 38: 'PHI', 19: 'HOU', 59: 'IND', 21: 'LAC', 22: 'SDC', 23: 'BUF', 24: 'LAL', 30: 'MIN', 26: 'MEM', 27: 'VAN', 28: 'MIA', 31: 'NOP', 32: 'NOK', 33: 'NOH', 34: 'NYK', 35: 'OKC', 36: 'SEA', 37: 'ORL', 39: 'SYR', 40: 'PHO', 41: 'POR', 42: 'SAC', 44: 'KCK', 45: 'CIN', 46: 'ROR', 47: 'SAS', 48: 'TOR', 49: 'UTA', 50: 'NOJ', 62: 'WAS', 53: 'CAP', 54: 'BAL', 57: 'AND', 60: 'SRS', 61: 'SLB', 63: 'WAT'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZe0HKGzCNGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST - Scraping a player games history\n",
        "aldridge_games = bc.players.get_game_logs('LaMarcus Aldridge', '2000-01-01', '2020-03-15')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe2Vez9lprLV",
        "colab_type": "code",
        "outputId": "4ee07a8a-27bd-4b72-d7a4-1723c9cd252d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "aldridge_games.drop(columns=['DATE']).head() # we don't really care about the date of the game, everything else is relevent"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE</th>\n",
              "      <th>TEAM</th>\n",
              "      <th>HOME/AWAY</th>\n",
              "      <th>OPPONENT</th>\n",
              "      <th>RESULT</th>\n",
              "      <th>GS</th>\n",
              "      <th>MP</th>\n",
              "      <th>FG</th>\n",
              "      <th>FGA</th>\n",
              "      <th>FG%</th>\n",
              "      <th>3P</th>\n",
              "      <th>3PA</th>\n",
              "      <th>3P%</th>\n",
              "      <th>FT</th>\n",
              "      <th>FTA</th>\n",
              "      <th>FT%</th>\n",
              "      <th>ORB</th>\n",
              "      <th>DRB</th>\n",
              "      <th>TRB</th>\n",
              "      <th>AST</th>\n",
              "      <th>STL</th>\n",
              "      <th>BLK</th>\n",
              "      <th>TOV</th>\n",
              "      <th>PF</th>\n",
              "      <th>PTS</th>\n",
              "      <th>GAME_SCORE</th>\n",
              "      <th>+/-</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21-116</td>\n",
              "      <td>POR</td>\n",
              "      <td>HOME</td>\n",
              "      <td>DAL</td>\n",
              "      <td>L (-7)</td>\n",
              "      <td>0</td>\n",
              "      <td>19:11</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>.556</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>9.7</td>\n",
              "      <td>+3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21-118</td>\n",
              "      <td>POR</td>\n",
              "      <td>AWAY</td>\n",
              "      <td>MIN</td>\n",
              "      <td>L (-12)</td>\n",
              "      <td>0</td>\n",
              "      <td>25:09</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>.600</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>.250</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5.5</td>\n",
              "      <td>-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>21-119</td>\n",
              "      <td>POR</td>\n",
              "      <td>AWAY</td>\n",
              "      <td>CLE</td>\n",
              "      <td>L (-13)</td>\n",
              "      <td>0</td>\n",
              "      <td>22:43</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>.750</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>16.4</td>\n",
              "      <td>+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>21-121</td>\n",
              "      <td>POR</td>\n",
              "      <td>AWAY</td>\n",
              "      <td>BOS</td>\n",
              "      <td>L (-28)</td>\n",
              "      <td>1</td>\n",
              "      <td>26:49</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>13.7</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>21-122</td>\n",
              "      <td>POR</td>\n",
              "      <td>AWAY</td>\n",
              "      <td>NJN</td>\n",
              "      <td>W (+18)</td>\n",
              "      <td>1</td>\n",
              "      <td>34:04</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>.556</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>10.2</td>\n",
              "      <td>+20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      AGE TEAM HOME/AWAY OPPONENT   RESULT GS  ... BLK TOV PF PTS GAME_SCORE  +/-\n",
              "4  21-116  POR      HOME      DAL   L (-7)  0  ...   0   0  2  10        9.7   +3\n",
              "5  21-118  POR      AWAY      MIN  L (-12)  0  ...   3   0  5   7        5.5  -10\n",
              "6  21-119  POR      AWAY      CLE  L (-13)  0  ...   0   0  5  13       16.4  +10\n",
              "7  21-121  POR      AWAY      BOS  L (-28)  1  ...   0   0  3  12       13.7   -3\n",
              "8  21-122  POR      AWAY      NJN  W (+18)  1  ...   2   1  4  12       10.2  +20\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzCtoEjuKD7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Pre-Processing function for a player games history\n",
        "def process_games_history(player_games):\n",
        "  player_games_duplicate = player_games.copy()\n",
        "  player_games_duplicate.drop(columns=[\"DATE\"], inplace=True)\n",
        "\n",
        "  # Process HOME/AWAY\n",
        "  player_games_duplicate.replace('HOME', 1, inplace=True)\n",
        "  player_games_duplicate.replace('AWAY', -1, inplace=True)\n",
        "\n",
        "  # Process TEAM & OPPONENT\n",
        "  for team in team2idx.keys():\n",
        "    player_games_duplicate.replace(team, team2idx[team], inplace=True)\n",
        "\n",
        "  # Process age\n",
        "  player_games_duplicate.replace(\"^((\\d\\d)-\\d*)\", \"\\\\2\", regex=True, inplace=True)\n",
        "\n",
        "  # Process Result\n",
        "  player_games_duplicate.replace(\"[L,W,(,)]\", \"\", regex=True, inplace=True)\n",
        "\n",
        "  # Process Minutes Played\n",
        "  player_games_duplicate.replace(\"[:]\", \".\",regex=True, inplace=True)\n",
        "\n",
        "  # Process NaN Percentage\n",
        "  player_games_duplicate.replace(np.NaN, 0, inplace=True)\n",
        "\n",
        "  # Arrange columns similarly for every player\n",
        "  player_games_duplicate = player_games_duplicate[  ['AGE','TEAM','OPPONENT','HOME/AWAY','GS','MP','FG',\n",
        "                                                    'FGA','FG%','3P','3PA','3P%','FT','FTA','FT%','ORB','DRB','TRB',\n",
        "                                                    'AST','STL','BLK','TOV','PF','PTS','RESULT','+/-','GAME_SCORE'] ]\n",
        "\n",
        "  return player_games_duplicate.astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLKvZ_hKRZqa",
        "colab_type": "code",
        "outputId": "32080a50-50f9-46cd-aacd-bef0a63a9767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "# TEST - Process a player's games history\n",
        "process_games_history(aldridge_games).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE</th>\n",
              "      <th>TEAM</th>\n",
              "      <th>OPPONENT</th>\n",
              "      <th>HOME/AWAY</th>\n",
              "      <th>GS</th>\n",
              "      <th>MP</th>\n",
              "      <th>FG</th>\n",
              "      <th>FGA</th>\n",
              "      <th>FG%</th>\n",
              "      <th>3P</th>\n",
              "      <th>3PA</th>\n",
              "      <th>3P%</th>\n",
              "      <th>FT</th>\n",
              "      <th>FTA</th>\n",
              "      <th>FT%</th>\n",
              "      <th>ORB</th>\n",
              "      <th>DRB</th>\n",
              "      <th>TRB</th>\n",
              "      <th>AST</th>\n",
              "      <th>STL</th>\n",
              "      <th>BLK</th>\n",
              "      <th>TOV</th>\n",
              "      <th>PF</th>\n",
              "      <th>PTS</th>\n",
              "      <th>RESULT</th>\n",
              "      <th>+/-</th>\n",
              "      <th>GAME_SCORE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.11</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.09</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>21.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.43</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>21.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.49</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-28.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>13.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>21.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.04</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    AGE  TEAM  OPPONENT  HOME/AWAY   GS  ...   PF   PTS  RESULT   +/-  GAME_SCORE\n",
              "4  21.0  41.0      11.0        1.0  0.0  ...  2.0  10.0    -7.0   3.0         9.7\n",
              "5  21.0  41.0      30.0       -1.0  0.0  ...  5.0   7.0   -12.0 -10.0         5.5\n",
              "6  21.0  41.0      10.0       -1.0  0.0  ...  5.0  13.0   -13.0  10.0        16.4\n",
              "7  21.0  41.0       4.0       -1.0  1.0  ...  3.0  12.0   -28.0  -3.0        13.7\n",
              "8  21.0  41.0       6.0       -1.0  1.0  ...  4.0  12.0    18.0  20.0        10.2\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "png_zjJWOiTo",
        "colab_type": "code",
        "outputId": "f6f9d00a-b6ba-42f7-cf6f-728d321dedb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "# TEST - Fetch a roster of a team from a given year\n",
        "player = list(bc.teams.get_roster('ATL',2000)['PLAYER'])\n",
        "player"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Drew Barry',\n",
              " 'Cal Bowdler',\n",
              " 'Bimbo Coles',\n",
              " 'Chris Crawford',\n",
              " 'LaPhonso Ellis',\n",
              " 'Dion Glover',\n",
              " 'Alan Henderson',\n",
              " 'Jim Jackson',\n",
              " 'Anthony Johnson',\n",
              " 'Roshown McLeod',\n",
              " 'Dikembe Mutombo',\n",
              " 'Isaiah Rider',\n",
              " 'Jason Terry',\n",
              " 'Lorenzen Wright']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfG9UkBISBhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function for getting a team rosters between 2000,2020\n",
        "def get_team_rosters(team):\n",
        "  rosters = {}\n",
        "  for i in range (2000,2021):\n",
        "    rosters[i] = list(bc.teams.get_roster(team,i)['PLAYER'])\n",
        "\n",
        "  return rosters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0_1G935WWzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function for extracting unique players names from the list of rosters\n",
        "def get_players(rosters):\n",
        "  players = set()\n",
        "  for roster in rosters.values():\n",
        "    for player in roster:\n",
        "      players.add(player)\n",
        "\n",
        "  return list(players)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "czXg649lc1oU",
        "outputId": "70cb17a7-c44a-48a5-c2df-64c3db2655c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "# Create a list of players between 2000-2021\n",
        "players = set()\n",
        "\n",
        "for team in team2idx.keys():\n",
        "  try:\n",
        "    rosters = get_team_rosters(team)\n",
        "    print('fetched players from: ', team)\n",
        "    for player in get_players(rosters):\n",
        "      players.add(player)\n",
        "  except:\n",
        "    print('unable to fetch players from: ', team)\n",
        "    continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unable to fetch players from:  ATL\n",
            "unable to fetch players from:  SLH\n",
            "unable to fetch players from:  MIL\n",
            "unable to fetch players from:  TCB\n",
            "unable to fetch players from:  BOS\n",
            "unable to fetch players from:  BRK\n",
            "unable to fetch players from:  NJN\n",
            "unable to fetch players from:  CHI\n",
            "unable to fetch players from:  CHO\n",
            "unable to fetch players from:  CHA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9lh02f6c2Z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save players-list to drive\n",
        "players_list = list(players)\n",
        "with open('/content/drive/data/players-list.p', 'wb') as fp:\n",
        "    pickle.dump(players_list, fp, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRTe43o1Uwr7",
        "colab_type": "code",
        "outputId": "06e35c12-7c0a-4a1e-92be-d2dea6801820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Loading the players-list\n",
        "with open('/content/drive/data/players-list.p', 'rb') as fp:\n",
        "    players_list = pickle.load(fp)\n",
        "\n",
        "len(players_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1906"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pAM2G_2I3fzB",
        "colab": {}
      },
      "source": [
        "# A function for getting  and processing a player games history between 2000-2020\n",
        "def get_performances(player):\n",
        "  player_games = bc.players.get_game_logs(player,'2000-01-01','2020-03-15')\n",
        "  return process_games_history(player_games).to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdz8ED1E3gtV",
        "colab_type": "code",
        "outputId": "a9cc416a-5ec6-434c-e0be-07c5ed7d2ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "# TEST - scrape a player games history\n",
        "get_performances(players_list[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 19. ,  10. ,  42. , ...,  -6. ,  -6. ,  13.1],\n",
              "       [ 19. ,  10. ,  29. , ..., -32. , -21. ,  -2.1],\n",
              "       [ 19. ,  10. ,  38. , ...,  -7. ,  -2. ,  16. ],\n",
              "       ...,\n",
              "       [ 21. ,  10. ,  13. , ..., -12. ,  -4. ,  -5.6],\n",
              "       [ 21. ,  10. ,   4. , ...,  -7. ,   6. ,   2.6],\n",
              "       [ 23. ,  15. ,  13. , ...,  32. ,   2. ,   2.6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEBYv454h5we",
        "colab_type": "code",
        "outputId": "e2edbb3a-75af-4a54-c810-f8e6fd188eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "# Scrape players stats between 2000-2020 and save it onto the drive\n",
        "# This takes a while and should only be ran once to grab the relevent data\n",
        "# (the percentage is roughly calculated just to keep track of progress)\n",
        "\n",
        "with open('/content/drive/data/players-stats2.p', 'rb') as dr:\n",
        "  sequences = pickle.load(dr)\n",
        "for i in range(len(players_list)):\n",
        "  try:\n",
        "    player = players_list[i]\n",
        "    if player not in sequences.keys():\n",
        "      sequences[player] = get_performances(player)\n",
        "    if i%20 == 0:\n",
        "      print('percentage finished: ', i/20)\n",
        "      with open('/content/drive/data/players-stats2.p', 'wb') as fp:\n",
        "        pickle.dump(sequences, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  except:\n",
        "    continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "percentage finished:  0.0\n",
            "percentage finished:  1.0\n",
            "percentage finished:  2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  sort=sort,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "percentage finished:  4.0\n",
            "percentage finished:  6.0\n",
            "percentage finished:  7.0\n",
            "percentage finished:  8.0\n",
            "percentage finished:  9.0\n",
            "percentage finished:  10.0\n",
            "percentage finished:  12.0\n",
            "percentage finished:  13.0\n",
            "percentage finished:  14.0\n",
            "percentage finished:  15.0\n",
            "percentage finished:  16.0\n",
            "percentage finished:  17.0\n",
            "percentage finished:  18.0\n",
            "percentage finished:  19.0\n",
            "percentage finished:  20.0\n",
            "percentage finished:  21.0\n",
            "percentage finished:  22.0\n",
            "percentage finished:  23.0\n",
            "percentage finished:  24.0\n",
            "percentage finished:  25.0\n",
            "percentage finished:  26.0\n",
            "percentage finished:  27.0\n",
            "percentage finished:  28.0\n",
            "percentage finished:  29.0\n",
            "percentage finished:  30.0\n",
            "percentage finished:  32.0\n",
            "percentage finished:  33.0\n",
            "percentage finished:  34.0\n",
            "percentage finished:  36.0\n",
            "percentage finished:  37.0\n",
            "percentage finished:  38.0\n",
            "percentage finished:  39.0\n",
            "percentage finished:  40.0\n",
            "percentage finished:  41.0\n",
            "percentage finished:  43.0\n",
            "percentage finished:  44.0\n",
            "percentage finished:  45.0\n",
            "percentage finished:  46.0\n",
            "percentage finished:  47.0\n",
            "percentage finished:  48.0\n",
            "percentage finished:  49.0\n",
            "percentage finished:  50.0\n",
            "percentage finished:  51.0\n",
            "percentage finished:  54.0\n",
            "percentage finished:  55.0\n",
            "percentage finished:  56.0\n",
            "percentage finished:  57.0\n",
            "percentage finished:  58.0\n",
            "percentage finished:  59.0\n",
            "percentage finished:  60.0\n",
            "percentage finished:  61.0\n",
            "percentage finished:  62.0\n",
            "percentage finished:  63.0\n",
            "percentage finished:  64.0\n",
            "percentage finished:  66.0\n",
            "percentage finished:  68.0\n",
            "percentage finished:  69.0\n",
            "percentage finished:  70.0\n",
            "percentage finished:  71.0\n",
            "percentage finished:  72.0\n",
            "percentage finished:  73.0\n",
            "percentage finished:  74.0\n",
            "percentage finished:  75.0\n",
            "percentage finished:  76.0\n",
            "percentage finished:  77.0\n",
            "percentage finished:  78.0\n",
            "percentage finished:  80.0\n",
            "percentage finished:  81.0\n",
            "percentage finished:  83.0\n",
            "percentage finished:  84.0\n",
            "percentage finished:  85.0\n",
            "percentage finished:  86.0\n",
            "percentage finished:  87.0\n",
            "percentage finished:  88.0\n",
            "percentage finished:  89.0\n",
            "percentage finished:  90.0\n",
            "percentage finished:  91.0\n",
            "percentage finished:  92.0\n",
            "percentage finished:  93.0\n",
            "percentage finished:  94.0\n",
            "percentage finished:  95.0\n",
            "CPU times: user 1h 27min 59s, sys: 28.8 s, total: 1h 28min 28s\n",
            "Wall time: 9h 51min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LXQweMGHVCv",
        "colab_type": "code",
        "outputId": "c348cf62-3a68-4992-839f-8f602df4ec2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "list(stats.items())[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Dajuan Wagner', array([[ 19. ,  10. ,  42. , ...,  -6. ,  -6. ,  13.1],\n",
              "        [ 19. ,  10. ,  29. , ..., -32. , -21. ,  -2.1],\n",
              "        [ 19. ,  10. ,  38. , ...,  -7. ,  -2. ,  16. ],\n",
              "        ...,\n",
              "        [ 21. ,  10. ,  13. , ..., -12. ,  -4. ,  -5.6],\n",
              "        [ 21. ,  10. ,   4. , ...,  -7. ,   6. ,   2.6],\n",
              "        [ 23. ,  15. ,  13. , ...,  32. ,   2. ,   2.6]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nYZw6Lf3UZ1",
        "colab_type": "text"
      },
      "source": [
        "**DATA Pre-Processing**\n",
        "\n",
        "Splitting the raw data into sequences of equal length in-order to train our network with batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo43bSENDdWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzfIedPMDqsK",
        "colab_type": "code",
        "outputId": "22cd6619-d9f9-410e-cc8b-ff735074b218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKxDX1OlThaw",
        "colab_type": "code",
        "outputId": "fc3ace24-eb4d-4ae5-b86c-87b8280e386b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load players stats from drive\n",
        "with open('/content/drive/My Drive/Deep_Learning_Final_Project/players-stats2.p', 'rb') as dr:\n",
        "  stats = pickle.load(dr)\n",
        "print(f'The data consists of 20 years of perosonal performance statisticss of: {len(stats)} players')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data consists of 20 years of perosonal performance statisticss of: 1619 players\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q_fPTRpms_K",
        "colab_type": "text"
      },
      "source": [
        "**Pre-Proccessing Functions:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOPEIa3jQm8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function for padding the inputs to be of n+1 rows where n is divisible by sequence_length\n",
        "def pad_input(games, seq_length):\n",
        "  nlines_to_pad = seq_length - (games.shape[0] % seq_length) + 1\n",
        "  padd = np.zeros( (nlines_to_pad, 27) )\n",
        "  padd[:, -1] = 1000 # for sepearating padding vectors from game vectors\n",
        "\n",
        "  return np.vstack( (games, padd) )\n",
        "\n",
        "# A function which pairs a game stats vector with the score that the player got in the next game\n",
        "def pair_labels(games):\n",
        "  next_game_scores = games[1:, -1]\n",
        "\n",
        "  return list(zip(games, next_game_scores))\n",
        "\n",
        "# A function for createing a list of data tuples of the form: ( [seq_data] , [seq_labels] )\n",
        "def create_data_tuples(games_labels, seq_length):\n",
        "  data = []\n",
        "\n",
        "  n_sequences = len(games_labels) / seq_length\n",
        "  sequences = np.array_split( np.array(games_labels), n_sequences)\n",
        "\n",
        "  for seq in sequences:\n",
        "    seq_data, seq_labels = zip(*seq)\n",
        "    seq_data = list(seq_data)\n",
        "    seq_labels = list(seq_labels)\n",
        "    data.append( (seq_data, seq_labels) )\n",
        "  \n",
        "  return data\n",
        "\n",
        "# A function for preparing sequences and corresponding labels out of the data\n",
        "def pre_process_data(data, seq_len):\n",
        "  sequences = []\n",
        "  labels = []\n",
        "  for games_history in data:\n",
        "    games = pad_input(games_history, seq_len)\n",
        "    games_labels = pair_labels(games)\n",
        "    games_labels = create_data_tuples(games_labels,seq_len)\n",
        "    cur_sequences = [ t[0] for t in games_labels ]\n",
        "    cur_labels = [ t[1] for t in games_labels ]\n",
        "    sequences += cur_sequences\n",
        "    labels += cur_labels\n",
        "  \n",
        "  return np.array(sequences), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Avl1OXQIbV",
        "colab_type": "code",
        "outputId": "29c67496-2495-4fbc-97e6-3f319f4dabdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Grab a set of games for TESTING\n",
        "test_games = stats['Kobe Bryant']\n",
        "test_games.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1131, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "efa9752c-5e7f-4f09-f8c5-1c8e03426eb0",
        "id": "0ryHAW-VZPCR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "# Padding TEST\n",
        "pad_test = pad_input(test_games, 10)\n",
        "print(pad_test)\n",
        "pad_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  21.    24.    21.  ...   24.     0.    16.3]\n",
            " [  21.    24.    21.  ...   17.     0.    21.8]\n",
            " [  21.    24.    17.  ...    4.     0.     2.7]\n",
            " ...\n",
            " [   0.     0.     0.  ...    0.     0.  1000. ]\n",
            " [   0.     0.     0.  ...    0.     0.  1000. ]\n",
            " [   0.     0.     0.  ...    0.     0.  1000. ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1141, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOQ-BhzrLAdi",
        "colab_type": "code",
        "outputId": "4290c4ef-88c6-4d04-b884-f8968319f644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "# Pair_labels TEST - you can see that each game vector is paired with the score of the player (the last columnd element) in the next game\n",
        "print(len(pad_test))\n",
        "\n",
        "test_games_labels = pair_labels(pad_test)\n",
        "print(len(test_games_labels))\n",
        "\n",
        "test_games_labels[:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1141\n",
            "1140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([21.   , 24.   , 21.   , -1.   ,  1.   , 37.04 , 12.   , 26.   ,\n",
              "          0.462,  0.   ,  1.   ,  0.   ,  5.   ,  7.   ,  0.714,  5.   ,\n",
              "          4.   ,  9.   ,  2.   ,  1.   ,  0.   ,  4.   ,  4.   , 29.   ,\n",
              "         24.   ,  0.   , 16.3  ]), 21.8),\n",
              " (array([21.   , 24.   , 21.   ,  1.   ,  1.   , 36.54 , 11.   , 22.   ,\n",
              "          0.5  ,  0.   ,  1.   ,  0.   ,  4.   ,  6.   ,  0.667,  3.   ,\n",
              "          7.   , 10.   ,  6.   ,  1.   ,  2.   ,  2.   ,  3.   , 26.   ,\n",
              "         17.   ,  0.   , 21.8  ]), 2.7),\n",
              " (array([21.   , 24.   , 17.   ,  1.   ,  1.   , 35.5  ,  5.   , 19.   ,\n",
              "          0.263,  1.   ,  4.   ,  0.25 ,  2.   ,  2.   ,  1.   ,  3.   ,\n",
              "          7.   , 10.   ,  4.   ,  1.   ,  0.   ,  5.   ,  5.   , 13.   ,\n",
              "          4.   ,  0.   ,  2.7  ]), 24.0),\n",
              " (array([21.   , 24.   , 36.   , -1.   ,  1.   , 42.49 , 11.   , 18.   ,\n",
              "          0.611,  5.   ,  7.   ,  0.714,  4.   ,  5.   ,  0.8  ,  0.   ,\n",
              "          6.   ,  6.   ,  1.   ,  3.   ,  1.   ,  3.   ,  4.   , 31.   ,\n",
              "         10.   ,  0.   , 24.   ]), 31.6)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twHHd2z-j5HG",
        "colab_type": "code",
        "outputId": "2d92c83f-ff69-4327-e908-38023e567d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# data tuples TEST\n",
        "data_tuples = create_data_tuples(test_games_labels, 10)\n",
        "\n",
        "len(data_tuples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haOMNiVnrai9",
        "colab_type": "code",
        "outputId": "4d2d543e-b4e0-4d6b-ee99-4cb08f4e4366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Pre Processing TEST\n",
        "data_sequences, data_scores = pre_process_data(stats.values(), seq_len=10)\n",
        "print(data_sequences.shape)\n",
        "print(data_scores.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45691, 10, 27)\n",
            "(45691, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6zzZsYW4ReM",
        "colab_type": "text"
      },
      "source": [
        "**Binning**\n",
        "\n",
        "Our model takes in a sequence of game stats vectors played by an NBA player, and for every such game in the sequence it tries to perdict the PER score that the player got in the next game.\n",
        "\n",
        "In order to best train and evaluate our model we decided to use binning and divide our target value (PER scores) into 5 ranges/classes (with a special class for padding vectors to overlook while training):\n",
        "\n",
        "*   Class 0: (-inf, 0)\n",
        "*   Class 1: [0,10)\n",
        "*   Class 2: [10,20)\n",
        "*   Class 3: [20,30)\n",
        "*   Class 4: [30,inf)\n",
        "*   Class 5: Padding vectors label (we are not interested in learning them)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xczyQnYK1fZx",
        "colab_type": "code",
        "outputId": "87786d62-3b42-49c5-86dd-cd3e9d3d9c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Print min, max scores\n",
        "print(f\"The minimum score of a player in our DataSet: {data_scores.min()}\")\n",
        "max_score = np.unique(np.sort(data_scores.flatten()))[-2] # The max in this list is actually 1000 - The padding \"score\", so we need the second max here\n",
        "print(f\"The maximum score of a player in our DataSet: {max_score}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The minimum score of a player in our DataSet: -11.7\n",
            "The maximum score of a player in our DataSet: 63.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSOK1HTFQ2Ld",
        "colab_type": "code",
        "outputId": "08c9c318-aa8a-4a34-cf90-2013ddf9c148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "from matplotlib import pyplot as plt \n",
        "   \n",
        "plt.hist(data_scores.flatten(), bins = [-15,-10,-5, 0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65] ) \n",
        "plt.title(\"Game Score distribution histogram\") \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZf1/czKdnU6rISUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b02WIj7EDIDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for binning the data labels\n",
        "def binning(data_scores):\n",
        "  data_labels = data_scores.copy()\n",
        "  for i in range(len(data_labels)):\n",
        "    for j in range(len(data_labels[i])):\n",
        "        if data_labels[i][j] < 0:\n",
        "          data_labels[i][j] = 0\n",
        "        elif data_labels[i][j] >= 0 and data_labels[i][j] < 10:\n",
        "          data_labels[i][j] = 1\n",
        "        elif data_labels[i][j] >= 10 and data_labels[i][j] < 20:\n",
        "          data_labels[i][j] = 2\n",
        "        elif data_labels[i][j] >= 20 and data_labels[i][j] < 30:\n",
        "          data_labels[i][j] = 3\n",
        "        elif data_labels[i][j] >= 30 and data_labels[i][j] < 800:\n",
        "          data_labels[i][j] = 4\n",
        "        elif data_labels[i][j] >= 800:\n",
        "          data_labels[i][j] = 5\n",
        "\n",
        "  return data_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnIzadFTENWm",
        "colab_type": "code",
        "outputId": "be88f21e-beef-4107-d7c5-b59de0d12eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# Binning TEST\n",
        "print(f'The scores before binning:\\n{data_scores}')\n",
        "print(f'\\nThe labels after binning:\\n{binning(data_scores)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The scores before binning:\n",
            "[[-2.10e+00  1.60e+01  1.65e+01 ...  2.34e+01 -1.60e+00  1.95e+01]\n",
            " [ 2.20e+00 -4.00e-01  3.10e+00 ...  1.60e+00  6.00e+00  1.19e+01]\n",
            " [ 5.40e+00 -1.30e+00  5.10e+00 ...  1.40e+01  1.29e+01  5.20e+00]\n",
            " ...\n",
            " [-9.00e-01  4.00e+00  3.20e+00 ...  3.00e-01  2.20e+00  8.00e-01]\n",
            " [-1.10e+00  4.00e-01 -5.00e-01 ...  2.70e+00  1.30e+00  2.00e-01]\n",
            " [-4.00e-01 -1.70e+00  1.00e+00 ...  2.10e+00  1.00e+03  1.00e+03]]\n",
            "\n",
            "The labels after binning:\n",
            "[[0. 2. 2. ... 3. 0. 2.]\n",
            " [1. 0. 1. ... 1. 1. 2.]\n",
            " [1. 0. 1. ... 2. 2. 1.]\n",
            " ...\n",
            " [0. 1. 1. ... 1. 1. 1.]\n",
            " [0. 1. 0. ... 1. 1. 1.]\n",
            " [0. 0. 1. ... 1. 5. 5.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VbD4dYwP1PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Divide the score into bins\n",
        "data_labels = binning(data_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hz2WCt7KhjW",
        "colab_type": "code",
        "outputId": "d056bfcf-2815-4b46-f1d8-6226d1d9c449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "bins = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']\n",
        "bins_count = np.bincount(data_labels.flatten().astype(int))\n",
        "ax.bar(bins,bins_count)\n",
        "plt.title(\"Classes distribution bar plot\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAFPCAYAAABtfuZZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azwV20G24W2Z",
        "colab_type": "text"
      },
      "source": [
        "**Datasets Division**\n",
        "\n",
        "After Pre-Processing our data and binning our labels we want to divide our dataset into 3 sets: train, validation and test.\n",
        "\n",
        "We also want to split our sets into batches, for that we'll use TensorDataset and DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WVaRaF44XSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br-bZL87eRm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def divide_dataset(data, labels, batch_size, train_portion = 0.8, validation_portion = 0.5):\n",
        "  # divide data into train and test\n",
        "  train_instances_number = int(train_portion * data.shape[0])\n",
        "\n",
        "  train_data = data[:train_instances_number]\n",
        "  train_labels = labels[:train_instances_number]\n",
        "\n",
        "  test_valid_data = data[train_instances_number:]\n",
        "  test_valid_labels = labels[train_instances_number:]\n",
        "\n",
        "  # divide test data into test and validation\n",
        "  valid_instances_number = int(VALIDATION_PORTION * test_valid_data.shape[0])\n",
        "\n",
        "  test_data = test_valid_data[:valid_instances_number]\n",
        "  test_labels = test_valid_labels[:valid_instances_number]\n",
        "  \n",
        "  valid_data = test_valid_data[valid_instances_number:]\n",
        "  valid_labels = test_valid_labels[valid_instances_number:]\n",
        "\n",
        "  # Wrap as datasets\n",
        "  train_set = TensorDataset(torch.from_numpy(train_data), torch.from_numpy(train_labels))\n",
        "  val_set = TensorDataset(torch.from_numpy(valid_data), torch.from_numpy(valid_labels))\n",
        "  test_set = TensorDataset(torch.from_numpy(test_data), torch.from_numpy(test_labels))\n",
        "  \n",
        "  # Wrap datasets with DataLoaders\n",
        "  train_loader = DataLoader(train_set, batch_size=batch_size)\n",
        "  val_loader = DataLoader(val_set, batch_size=batch_size)\n",
        "  test_loader = DataLoader(test_set, batch_size=batch_size)\n",
        "  \n",
        "  return train_loader, val_loader, test_loader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--r4BX6fCd57",
        "colab_type": "code",
        "outputId": "f6e6b3d3-ffd9-4bf5-d643-12d521c59d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "# Dataset Division TEST\n",
        "TRAIN_PORTION = 0.8\n",
        "VALIDATION_PORTION = 0.5 # out of the test instances\n",
        "BATCH_SIZE = 45\n",
        "\n",
        "train_loader, val_loader, test_loader = divide_dataset(data_sequences, data_labels, BATCH_SIZE, TRAIN_PORTION, VALIDATION_PORTION)\n",
        "\n",
        "print(f'Number of train instances:  {len(train_loader.dataset)}')\n",
        "print(f'Number of validation instances:  {len(val_loader.dataset)}')\n",
        "print(f'Number of test instances:  {len(test_loader.dataset)}')\n",
        "\n",
        "print(f'Total number of instances: {data_sequences.shape[0]}')\n",
        "\n",
        "batch_data, batch_labels = iter(train_loader).next()\n",
        "\n",
        "print(f'Example data batch shape: {batch_data.shape}')\n",
        "print(f'Example labels batch shape: {batch_labels.shape}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train instances:  36552\n",
            "Number of validation instances:  4570\n",
            "Number of test instances:  4569\n",
            "Total number of instances: 45691\n",
            "Example data batch shape: torch.Size([45, 10, 27])\n",
            "Example labels batch shape: torch.Size([45, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu4Mqdrwk6Ps",
        "colab_type": "text"
      },
      "source": [
        "# **Defining our Network and preparing for Training**\n",
        "\n",
        "Now we're finally at the point where we define our network.\n",
        "we'll define a pretty simple LSTM Network which we will later experiment with in different settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2bg88ilMYxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TK_jk6yk6vQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Definition\n",
        "class NBAPredictionLSTM(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim, \n",
        "                 n_layers,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers = n_layers, dropout = dropout, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, sequence):\n",
        "\n",
        "        #pass sequence into LSTM\n",
        "        outputs, _ = self.lstm(sequence)\n",
        "        \n",
        "        #we use our outputs to make a prediction of what the tags should be\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        \n",
        "        return predictions\n",
        "    # Weight initialization from normal distribution\n",
        "    def init_weights(self):\n",
        "      for name, param in self.named_parameters():\n",
        "        nn.init.normal_(param.data, mean = 0, std = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNnpuf586NvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function for measuring the accuracy of a model over a set of batches\n",
        "def accuracy(model, loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(loader):\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.cuda().float()\n",
        "      labels = labels.cuda().long()\n",
        "      \n",
        "      outputs = model(inputs)\n",
        "      outputs = outputs.view(-1,5)\n",
        "      labels = labels.view(-1)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  return (correct / total) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ8TtQF4zVI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        # get inputs and put them on GPU\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward + reshape for loss function + backward + optimize\n",
        "        outputs  = model(inputs)\n",
        "        outputs = outputs.view(-1, 5) # reshape outputs from [batch_size, seq_len, output_size] -> [batch_size * seq_len, output_size]\n",
        "        labels = labels.view(-1) # reshape labels from [batch_size, seq_len] -> [batch_size * seq_len]\n",
        "\n",
        "        # back prop + optimize\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate epoch stats\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    acc = accuracy(model, loader)\n",
        "    return epoch_loss/len(loader), acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNc5yTgJKKa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, n_epochs, model_name):\n",
        "  \n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  valid_acc = 0\n",
        "\n",
        "  best_valid_acc = accuracy(model, val_loader)\n",
        "  print(f'The accuracy of the model over the validation set before training: {best_valid_acc:.4}%')\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      \n",
        "      train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "      valid_acc = accuracy(model, val_loader)\n",
        "      \n",
        "      if valid_acc > best_valid_acc:\n",
        "          best_valid_acc = valid_acc\n",
        "          torch.save(model.state_dict(), model_name)\n",
        "      \n",
        "      print(f'Epoch {epoch+1:02} Summary:')\n",
        "      print(f'\\t\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
        "      print(f'\\t\\tVal. Acc: {valid_acc:.2f}%')\n",
        "\n",
        "  return  train_loss, train_acc, valid_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YarY--AcJ9UH",
        "colab_type": "text"
      },
      "source": [
        "# **Experimenting with our Network**\n",
        "\n",
        "After defining our network and laying the ground for training we'll start experimenting with it by using it in different settings.\n",
        "\n",
        "We want to check our hpyothesis - a LSTM is well suited for predicting successive game scores.\n",
        "\n",
        "In order to test this hypothesis we'll run 3 experiments:\n",
        "\n",
        "\n",
        "1.   **Mini Batch Size** - First, we'll try to determine the best batch size for training\n",
        "2.   **Sequence Length Size** - Next, we'll try to determine the best sequence length to use\n",
        "3.   **Feed Forward Comparison** - Finally, we'll build a simple Feed Forward Network and compare it's performance to our LSTM model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xzVgsXBbnoz",
        "colab_type": "text"
      },
      "source": [
        "**Experiment #1**\n",
        "\n",
        "Best Batch Size out of: [16, 32, 64]\n",
        "\n",
        "\n",
        "\n",
        "MODEL:\n",
        "\n",
        "*   Sequence Length: 10 games\n",
        "*   Hidden Dim: 128\n",
        "*   Number of LSTM Layers: 2\n",
        "*   Dropout probability: 0.25\n",
        "*   Learning Rate: 0.005\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Y-yQ5R2sjt",
        "colab_type": "text"
      },
      "source": [
        "**Batch Size = 16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adX8f2TdKv6O",
        "colab_type": "code",
        "outputId": "7a678252-0f3e-41d3-b144-558883103064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "data_sequences, data_scores = pre_process_data(stats.values(), 10)\n",
        "data_labels = binning(data_scores)\n",
        "\n",
        "TRAIN_PORTION = 0.8\n",
        "VALIDATION_PORTION = 0.5 # out of the test instances\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_loader, val_loader, test_loader = divide_dataset(data_sequences, data_labels, BATCH_SIZE, TRAIN_PORTION, VALIDATION_PORTION)\n",
        "\n",
        "print(f'Number of train instances:  {len(train_loader.dataset)}')\n",
        "print(f'Number of validation instances:  {len(val_loader.dataset)}')\n",
        "print(f'Number of test instances:  {len(test_loader.dataset)}')\n",
        "print(f'Total number of instances: {data_sequences.shape[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train instances:  36552\n",
            "Number of validation instances:  4570\n",
            "Number of test instances:  4569\n",
            "Total number of instances: 45691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK7ZP-wlxmfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model\n",
        "\n",
        "PAD_INDEX = 5\n",
        "INPUT_DIM = 27\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 5\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.25\n",
        "LEARNING_RATE=0.005\n",
        "\n",
        "batch_test_model_1 = NBAPredictionLSTM(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).cuda()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_INDEX) # ignore padding labels when calculating loss\n",
        "optimizer = torch.optim.Adam(batch_test_model_1.parameters(), lr=LEARNING_RATE)\n",
        "batch_test_model_1.init_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwLb-WTbHFLl",
        "colab_type": "code",
        "outputId": "abddbe69-fbf7-45eb-e7a5-9651989e848f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "# Train the Model\n",
        "batch_train_loss_1, batch_train_acc_1, batch_val_acc_1 = train_model(batch_test_model_1, 10, 'NBA-LSTM-V1.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model over the validation set before training: 12.24%\n",
            "Epoch 01 Summary:\n",
            "\t\tTrain Loss: 0.997 | Train Acc: 55.43%\n",
            "\t\tVal. Acc: 54.56%\n",
            "Epoch 02 Summary:\n",
            "\t\tTrain Loss: 0.982 | Train Acc: 56.68%\n",
            "\t\tVal. Acc: 55.79%\n",
            "Epoch 03 Summary:\n",
            "\t\tTrain Loss: 0.978 | Train Acc: 57.87%\n",
            "\t\tVal. Acc: 56.95%\n",
            "Epoch 04 Summary:\n",
            "\t\tTrain Loss: 0.975 | Train Acc: 57.69%\n",
            "\t\tVal. Acc: 56.71%\n",
            "Epoch 05 Summary:\n",
            "\t\tTrain Loss: 0.974 | Train Acc: 57.87%\n",
            "\t\tVal. Acc: 56.96%\n",
            "Epoch 06 Summary:\n",
            "\t\tTrain Loss: 0.973 | Train Acc: 58.19%\n",
            "\t\tVal. Acc: 57.17%\n",
            "Epoch 07 Summary:\n",
            "\t\tTrain Loss: 0.972 | Train Acc: 58.32%\n",
            "\t\tVal. Acc: 57.26%\n",
            "Epoch 08 Summary:\n",
            "\t\tTrain Loss: 0.970 | Train Acc: 58.32%\n",
            "\t\tVal. Acc: 57.31%\n",
            "Epoch 09 Summary:\n",
            "\t\tTrain Loss: 0.970 | Train Acc: 58.40%\n",
            "\t\tVal. Acc: 57.29%\n",
            "Epoch 10 Summary:\n",
            "\t\tTrain Loss: 0.969 | Train Acc: 58.34%\n",
            "\t\tVal. Acc: 57.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3MKJxAym12K",
        "colab_type": "code",
        "outputId": "079006fc-c45c-418e-a047-32c2329e35fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "batch_test_acc_1 = accuracy(batch_test_model_1, test_loader)\n",
        "print(f\"This model's accuracy over the Test set: {batch_test_acc_1:.4}%\")\n",
        "print(f\"This model's average accuracy over the Train set: {batch_train_acc_1:.4}%\")\n",
        "print(f\"This model's average accuracy over the Validation set: {batch_val_acc_1:.4}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This model's accuracy over the Test set: 59.46%\n",
            "This model's average accuracy over the Train set: 58.34%\n",
            "This model's average accuracy over the Validation set: 57.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heDWO734xejT",
        "colab_type": "text"
      },
      "source": [
        "**Batch Size = 32**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUm46SFHxe4z",
        "colab_type": "code",
        "outputId": "078deccf-7e4b-40c4-de21-4f0c982b5499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader, val_loader, test_loader = divide_dataset(data_sequences, data_labels, BATCH_SIZE, TRAIN_PORTION, VALIDATION_PORTION)\n",
        "\n",
        "print(f'Number of train instances:  {len(train_loader.dataset)}')\n",
        "print(f'Number of validation instances:  {len(val_loader.dataset)}')\n",
        "print(f'Number of test instances:  {len(test_loader.dataset)}')\n",
        "print(f'Total number of instances: {data_sequences.shape[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train instances:  36552\n",
            "Number of validation instances:  4570\n",
            "Number of test instances:  4569\n",
            "Total number of instances: 45691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcuQkssRxm9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model\n",
        "batch_test_model_2 = NBAPredictionLSTM(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).cuda()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_INDEX) # ignore padding labels when calculating loss\n",
        "optimizer = torch.optim.Adam(batch_test_model_2.parameters(), lr=LEARNING_RATE)\n",
        "batch_test_model_2.init_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thz826fayEyz",
        "colab_type": "code",
        "outputId": "d6a2da16-d7b5-48fd-997f-ace202167413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "batch_train_loss_2, batch_train_acc_2, batch_val_acc_2 = train_model(batch_test_model_2, 10, 'NBA-LSTM-V2.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model over the validation set before training: 20.73%\n",
            "Epoch 01 Summary:\n",
            "\t\tTrain Loss: 0.998 | Train Acc: 57.73%\n",
            "\t\tVal. Acc: 56.77%\n",
            "Epoch 02 Summary:\n",
            "\t\tTrain Loss: 0.980 | Train Acc: 58.20%\n",
            "\t\tVal. Acc: 57.26%\n",
            "Epoch 03 Summary:\n",
            "\t\tTrain Loss: 0.973 | Train Acc: 58.35%\n",
            "\t\tVal. Acc: 57.21%\n",
            "Epoch 04 Summary:\n",
            "\t\tTrain Loss: 0.972 | Train Acc: 58.42%\n",
            "\t\tVal. Acc: 57.23%\n",
            "Epoch 05 Summary:\n",
            "\t\tTrain Loss: 0.970 | Train Acc: 58.41%\n",
            "\t\tVal. Acc: 57.26%\n",
            "Epoch 06 Summary:\n",
            "\t\tTrain Loss: 0.969 | Train Acc: 58.44%\n",
            "\t\tVal. Acc: 57.26%\n",
            "Epoch 07 Summary:\n",
            "\t\tTrain Loss: 0.968 | Train Acc: 58.46%\n",
            "\t\tVal. Acc: 57.26%\n",
            "Epoch 08 Summary:\n",
            "\t\tTrain Loss: 0.967 | Train Acc: 58.48%\n",
            "\t\tVal. Acc: 57.30%\n",
            "Epoch 09 Summary:\n",
            "\t\tTrain Loss: 0.966 | Train Acc: 58.53%\n",
            "\t\tVal. Acc: 57.30%\n",
            "Epoch 10 Summary:\n",
            "\t\tTrain Loss: 0.966 | Train Acc: 58.49%\n",
            "\t\tVal. Acc: 57.43%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLY9ERV0n2eZ",
        "colab_type": "code",
        "outputId": "1c278afc-10e8-4dd0-981c-6f2f7340a4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "batch_test_acc_2 = accuracy(batch_test_model_2, test_loader)\n",
        "print(f\"This model's accuracy over the Test set: {batch_test_acc_2:.4}%\")\n",
        "print(f\"This model's average accuracy over the Train set: {batch_train_acc_2:.4}%\")\n",
        "print(f\"This model's average accuracy over the Validation set: {batch_val_acc_2:.4}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This model's accuracy over the Test set: 59.53%\n",
            "This model's average accuracy over the Train set: 58.49%\n",
            "This model's average accuracy over the Validation set: 57.43%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q39CY9uys3m",
        "colab_type": "text"
      },
      "source": [
        "**Batch Size = 64**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocZ_NxV_ytVc",
        "colab_type": "code",
        "outputId": "5697f95e-d237-45f9-da9f-f5c48ca17ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader, val_loader, test_loader = divide_dataset(data_sequences, data_labels, BATCH_SIZE, TRAIN_PORTION, VALIDATION_PORTION)\n",
        "\n",
        "print(f'Number of train instances:  {len(train_loader.dataset)}')\n",
        "print(f'Number of validation instances:  {len(val_loader.dataset)}')\n",
        "print(f'Number of test instances:  {len(test_loader.dataset)}')\n",
        "print(f'Total number of instances: {data_sequences.shape[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train instances:  36552\n",
            "Number of validation instances:  4570\n",
            "Number of test instances:  4569\n",
            "Total number of instances: 45691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cl0dT3aPy-Rj",
        "colab": {}
      },
      "source": [
        "# Create a model\n",
        "\n",
        "batch_test_model_3 = NBAPredictionLSTM(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).cuda()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_INDEX) # ignore padding labels when calculating loss\n",
        "optimizer = torch.optim.Adam(batch_test_model_3.parameters(), lr=LEARNING_RATE)\n",
        "batch_test_model_3.init_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txtBdzTXy-xz",
        "colab_type": "code",
        "outputId": "cda77f05-23e6-47bd-e365-f9cc15c40915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "batch_train_loss_3, batch_train_acc_3, batch_val_acc_3 = train_model(batch_test_model_3, 10, 'NBA-LSTM-V3.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model over the validation set before training: 47.7%\n",
            "Epoch 01 Summary:\n",
            "\t\tTrain Loss: 0.996 | Train Acc: 58.13%\n",
            "\t\tVal. Acc: 57.15%\n",
            "Epoch 02 Summary:\n",
            "\t\tTrain Loss: 0.977 | Train Acc: 58.32%\n",
            "\t\tVal. Acc: 57.27%\n",
            "Epoch 03 Summary:\n",
            "\t\tTrain Loss: 0.972 | Train Acc: 58.39%\n",
            "\t\tVal. Acc: 57.33%\n",
            "Epoch 04 Summary:\n",
            "\t\tTrain Loss: 0.969 | Train Acc: 58.43%\n",
            "\t\tVal. Acc: 57.36%\n",
            "Epoch 05 Summary:\n",
            "\t\tTrain Loss: 0.967 | Train Acc: 58.45%\n",
            "\t\tVal. Acc: 57.31%\n",
            "Epoch 06 Summary:\n",
            "\t\tTrain Loss: 0.965 | Train Acc: 58.51%\n",
            "\t\tVal. Acc: 57.43%\n",
            "Epoch 07 Summary:\n",
            "\t\tTrain Loss: 0.964 | Train Acc: 58.49%\n",
            "\t\tVal. Acc: 57.34%\n",
            "Epoch 08 Summary:\n",
            "\t\tTrain Loss: 0.964 | Train Acc: 58.49%\n",
            "\t\tVal. Acc: 57.32%\n",
            "Epoch 09 Summary:\n",
            "\t\tTrain Loss: 0.963 | Train Acc: 58.54%\n",
            "\t\tVal. Acc: 57.38%\n",
            "Epoch 10 Summary:\n",
            "\t\tTrain Loss: 0.962 | Train Acc: 58.55%\n",
            "\t\tVal. Acc: 57.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCnHJub9Zuby",
        "colab_type": "code",
        "outputId": "51603e11-480e-455e-cbe6-32920f748340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "batch_test_acc_3 = accuracy(batch_test_model_3, test_loader)\n",
        "print(f\"This model's accuracy over the Test set: {batch_test_acc_3:.4}%\")\n",
        "print(f\"This model's average accuracy over the Train set: {batch_train_acc_3:.4}%\")\n",
        "print(f\"This model's average accuracy over the Validation set: {batch_val_acc_3:.4}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This model's accuracy over the Test set: 59.58%\n",
            "This model's average accuracy over the Train set: 58.55%\n",
            "This model's average accuracy over the Validation set: 57.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76tVgvrl2FV1",
        "colab_type": "text"
      },
      "source": [
        "**Experiment #2**\n",
        "\n",
        "Best sequence length out of: [2, 4, 8, 16, 32]\n",
        "\n",
        "MODEL:\n",
        "\n",
        "*  Batch Size: 32\n",
        "*  Hidden Dim: 128\n",
        "*  Number of LSTM Layers: 2\n",
        "*  Dropout probability: 0.25\n",
        "*  Learning Rate: 0.005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iamHSEgh8YVP",
        "colab_type": "text"
      },
      "source": [
        "**Sequnce Length = 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24awVbdv8Lqe",
        "colab_type": "code",
        "outputId": "35c1840f-41d5-4a9e-eb71-a31f02d611d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "data_sequences, data_scores = pre_process_data(stats.values(), 2)\n",
        "data_labels = binning(data_scores)\n",
        "\n",
        "TRAIN_PORTION = 0.8\n",
        "VALIDATION_PORTION = 0.5 # out of the test instances\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader, val_loader, test_loader = divide_dataset(data_sequences, data_labels, BATCH_SIZE, TRAIN_PORTION, VALIDATION_PORTION)\n",
        "\n",
        "print(f'Number of train instances:  {len(train_loader.dataset)}')\n",
        "print(f'Number of validation instances:  {len(val_loader.dataset)}')\n",
        "print(f'Number of test instances:  {len(test_loader.dataset)}')\n",
        "print(f'Total number of instances: {data_sequences.shape[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train instances:  180235\n",
            "Number of validation instances:  22530\n",
            "Number of test instances:  22529\n",
            "Total number of instances: 225294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuhHQxCf8Mc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model\n",
        "\n",
        "PAD_INDEX = 5\n",
        "INPUT_DIM = 27\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 5\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.25\n",
        "LEARNING_RATE=0.005\n",
        "\n",
        "seq_test_model_1 = NBAPredictionLSTM(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).cuda()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_INDEX) # ignore padding labels when calculating loss\n",
        "optimizer = torch.optim.Adam(seq_test_model_1.parameters(), lr=LEARNING_RATE)\n",
        "seq_test_model_1.init_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lHlOGPO8rhF",
        "colab_type": "code",
        "outputId": "62236f45-3d0a-410c-c8d5-1b26420455d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "seq_train_loss_1, seq_train_acc_1, seq_val_acc_1 = train_model(seq_test_model_1, 10, 'NBA-LSTM-Seq-V1.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model over the validation set before training: 52.52%\n",
            "Epoch 01 Summary:\n",
            "\t\tTrain Loss: 1.019 | Train Acc: 51.56%\n",
            "\t\tVal. Acc: 50.42%\n",
            "Epoch 02 Summary:\n",
            "\t\tTrain Loss: 1.003 | Train Acc: 53.92%\n",
            "\t\tVal. Acc: 52.91%\n",
            "Epoch 03 Summary:\n",
            "\t\tTrain Loss: 1.000 | Train Acc: 55.40%\n",
            "\t\tVal. Acc: 54.37%\n",
            "Epoch 04 Summary:\n",
            "\t\tTrain Loss: 1.000 | Train Acc: 54.95%\n",
            "\t\tVal. Acc: 53.79%\n",
            "Epoch 05 Summary:\n",
            "\t\tTrain Loss: 0.998 | Train Acc: 55.87%\n",
            "\t\tVal. Acc: 55.00%\n",
            "Epoch 06 Summary:\n",
            "\t\tTrain Loss: 0.997 | Train Acc: 57.18%\n",
            "\t\tVal. Acc: 56.34%\n",
            "Epoch 07 Summary:\n",
            "\t\tTrain Loss: 0.996 | Train Acc: 57.26%\n",
            "\t\tVal. Acc: 56.49%\n",
            "Epoch 08 Summary:\n",
            "\t\tTrain Loss: 0.996 | Train Acc: 57.18%\n",
            "\t\tVal. Acc: 56.28%\n",
            "Epoch 09 Summary:\n",
            "\t\tTrain Loss: 0.997 | Train Acc: 56.33%\n",
            "\t\tVal. Acc: 55.26%\n",
            "Epoch 10 Summary:\n",
            "\t\tTrain Loss: 0.996 | Train Acc: 56.74%\n",
            "\t\tVal. Acc: 55.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BplqODZO8xXL",
        "colab_type": "code",
        "outputId": "d0326a17-f6d3-47f6-9256-151f770ef245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Print Model's accuracy over Test Set\n",
        "seq_test_acc_1 = accuracy(seq_test_model_1, test_loader)\n",
        "print(f\"This model's accuracy over the Test set: {seq_test_acc_1:.4}%\")\n",
        "print(f\"This model's accuracy over the Train set: {seq_train_acc_1:.4}%\")\n",
        "print(f\"This model's accuracy over the Validation set: {seq_val_acc_1:.4}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This model's accuracy over the Test set: 58.36%\n",
            "This model's accuracy over the Train set: 56.74%\n",
            "This model's accuracy over the Validation set: 55.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmhydy9wAycK",
        "colab_type": "text"
      },
      "source": [
        "**Sequnce Length = 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3iZgky3Ay2L",
        "colab_type": "code",
        "outputId": "a224ead1-3dff-457a-d1fe-f042909b5846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "data_sequences, data_scores = pre_process_data(stats.values(), 4)\n",
        "data_labels = binning(data_scores)\n",
        "\n",
        "train_loader, val_loader, test_loader = divide_dataset(data_sequences, data_labels, BATCH_SIZE, TRAIN_PORTION, VALIDATION_PORTION)\n",
        "\n",
        "print(f'Number of train instances:  {len(train_loader.dataset)}')\n",
        "print(f'Number of validation instances:  {len(val_loader.dataset)}')\n",
        "print(f'Number of test instances:  {len(test_loader.dataset)}')\n",
        "print(f'Total number of instances: {data_sequences.shape[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train instances:  90426\n",
            "Number of validation instances:  11304\n",
            "Number of test instances:  11303\n",
            "Total number of instances: 113033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN4PigwSBN92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model\n",
        "\n",
        "seq_test_model_2 = NBAPredictionLSTM(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).cuda()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_INDEX) # ignore padding labels when calculating loss\n",
        "optimizer = torch.optim.Adam(seq_test_model_2.parameters(), lr=LEARNING_RATE)\n",
        "seq_test_model_2.init_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JmX5_yVBcnK",
        "colab_type": "code",
        "outputId": "4a398198-7244-48e4-9486-8b2ae1d10bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "seq_train_loss_2, seq_train_acc_2, seq_val_acc_2 = train_model(seq_test_model_2, 10, 'NBA-LSTM-Seq-V2.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model over the validation set before training: 10.27%\n",
            "Epoch 01 Summary:\n",
            "\t\tTrain Loss: 1.012 | Train Acc: 53.93%\n",
            "\t\tVal. Acc: 52.93%\n",
            "Epoch 02 Summary:\n",
            "\t\tTrain Loss: 0.993 | Train Acc: 56.78%\n",
            "\t\tVal. Acc: 55.78%\n",
            "Epoch 03 Summary:\n",
            "\t\tTrain Loss: 0.990 | Train Acc: 57.29%\n",
            "\t\tVal. Acc: 56.33%\n",
            "Epoch 04 Summary:\n",
            "\t\tTrain Loss: 0.988 | Train Acc: 57.89%\n",
            "\t\tVal. Acc: 56.91%\n",
            "Epoch 05 Summary:\n",
            "\t\tTrain Loss: 0.986 | Train Acc: 58.06%\n",
            "\t\tVal. Acc: 57.08%\n",
            "Epoch 06 Summary:\n",
            "\t\tTrain Loss: 0.985 | Train Acc: 58.17%\n",
            "\t\tVal. Acc: 57.17%\n",
            "Epoch 07 Summary:\n",
            "\t\tTrain Loss: 0.985 | Train Acc: 58.23%\n",
            "\t\tVal. Acc: 57.34%\n",
            "Epoch 08 Summary:\n",
            "\t\tTrain Loss: 0.984 | Train Acc: 58.31%\n",
            "\t\tVal. Acc: 57.38%\n",
            "Epoch 09 Summary:\n",
            "\t\tTrain Loss: 0.983 | Train Acc: 58.54%\n",
            "\t\tVal. Acc: 57.50%\n",
            "Epoch 10 Summary:\n",
            "\t\tTrain Loss: 0.983 | Train Acc: 58.49%\n",
            "\t\tVal. Acc: 57.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPSzOMinCdCR",
        "colab_type": "code",
        "outputId": "d700233c-2b2c-4fad-950f-f0aab07ecdc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Print Model's accuracy over Test Set\n",
        "seq_test_acc_2 = accuracy(seq_test_model_2, test_loader)\n",
        "print(f\"This model's accuracy over the Test set: {seq_test_acc_2:.4}%\")\n",
        "print(f\"This model's accuracy over the Train set: {seq_train_acc_2:.4}%\")\n",
        "print(f\"This model's accuracy over the Validation set: {seq_val_acc_2:.4}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This model's accuracy over the Test set: 59.85%\n",
            "This model's accuracy over the Train set: 58.49%\n",
            "This model's accuracy over the Validation set: 57.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-hBPTqGF_6B",
        "colab_type": "text"
      },
      "source": [
        "**Sequnce Length = 8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1E0eLNcGBio",
        "colab_type": "code",
        "outputId": "42f18451-fcbc-4267-e7ed-522918c4de0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "data_sequences, data_scores = pre_process_data(stats.values(), 8)\n",
        "data_labels = binning(data_scores)\n",
        "\n",
        "train_loader, val_loader, test_loader = divide_dataset(data_sequences, data_labels, BATCH_SIZE, TRAIN_PORTION, VALIDATION_PORTION)\n",
        "\n",
        "print(f'Number of train instances:  {len(train_loader.dataset)}')\n",
        "print(f'Number of validation instances:  {len(val_loader.dataset)}')\n",
        "print(f'Number of test instances:  {len(test_loader.dataset)}')\n",
        "print(f'Total number of instances: {data_sequences.shape[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train instances:  45551\n",
            "Number of validation instances:  5694\n",
            "Number of test instances:  5694\n",
            "Total number of instances: 56939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep3K4Q4rGJ-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model\n",
        "\n",
        "seq_test_model_3 = NBAPredictionLSTM(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).cuda()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_INDEX) # ignore padding labels when calculating loss\n",
        "optimizer = torch.optim.Adam(seq_test_model_3.parameters(), lr=LEARNING_RATE)\n",
        "seq_test_model_3.init_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzWTgS-VGN4x",
        "colab_type": "code",
        "outputId": "28dc32b1-1a26-43d0-8587-0812e068898e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "seq_train_loss_3, seq_train_acc_3, seq_val_acc_3 = train_model(seq_test_model_3, 10, 'NBA-LSTM-Seq-V3.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model over the validation set before training: 10.78%\n",
            "Epoch 01 Summary:\n",
            "\t\tTrain Loss: 1.002 | Train Acc: 57.16%\n",
            "\t\tVal. Acc: 56.02%\n",
            "Epoch 02 Summary:\n",
            "\t\tTrain Loss: 0.984 | Train Acc: 57.77%\n",
            "\t\tVal. Acc: 56.84%\n",
            "Epoch 03 Summary:\n",
            "\t\tTrain Loss: 0.979 | Train Acc: 58.09%\n",
            "\t\tVal. Acc: 57.18%\n",
            "Epoch 04 Summary:\n",
            "\t\tTrain Loss: 0.975 | Train Acc: 58.34%\n",
            "\t\tVal. Acc: 57.47%\n",
            "Epoch 05 Summary:\n",
            "\t\tTrain Loss: 0.974 | Train Acc: 58.31%\n",
            "\t\tVal. Acc: 57.33%\n",
            "Epoch 06 Summary:\n",
            "\t\tTrain Loss: 0.973 | Train Acc: 58.46%\n",
            "\t\tVal. Acc: 57.51%\n",
            "Epoch 07 Summary:\n",
            "\t\tTrain Loss: 0.972 | Train Acc: 58.44%\n",
            "\t\tVal. Acc: 57.52%\n",
            "Epoch 08 Summary:\n",
            "\t\tTrain Loss: 0.971 | Train Acc: 58.43%\n",
            "\t\tVal. Acc: 57.50%\n",
            "Epoch 09 Summary:\n",
            "\t\tTrain Loss: 0.970 | Train Acc: 58.50%\n",
            "\t\tVal. Acc: 57.61%\n",
            "Epoch 10 Summary:\n",
            "\t\tTrain Loss: 0.970 | Train Acc: 58.56%\n",
            "\t\tVal. Acc: 57.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3sqLStQGOgS",
        "colab_type": "code",
        "outputId": "040aa399-4833-4021-acc0-fb86403c5a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Print Model's accurcy stats\n",
        "seq_test_acc_3 = accuracy(seq_test_model_3, test_loader)\n",
        "print(f\"This model's accuracy over the Test set: {seq_test_acc_3:.4}%\")\n",
        "print(f\"This model's accuracy over the Train set: {seq_train_acc_3:.4}%\")\n",
        "print(f\"This model's accuracy over the Validation set: {seq_val_acc_3:.4}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This model's accuracy over the Test set: 57.25%\n",
            "This model's accuracy over the Train set: 58.56%\n",
            "This model's accuracy over the Validation set: 57.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oMT7GUXHCMZ",
        "colab_type": "text"
      },
      "source": [
        "**Sequnce Length = 16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxmQx_twHDfY",
        "colab_type": "code",
        "outputId": "3024d85e-bb4b-4736-c85d-645657792f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "data_sequences, data_scores = pre_process_data(stats.values(), 16)\n",
        "data_labels = binning(data_scores)\n",
        "\n",
        "train_loader, val_loader, test_loader = divide_dataset(data_sequences, data_labels, BATCH_SIZE, TRAIN_PORTION, VALIDATION_PORTION)\n",
        "\n",
        "print(f'Number of train instances:  {len(train_loader.dataset)}')\n",
        "print(f'Number of validation instances:  {len(val_loader.dataset)}')\n",
        "print(f'Number of test instances:  {len(test_loader.dataset)}')\n",
        "print(f'Total number of instances: {data_sequences.shape[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train instances:  23099\n",
            "Number of validation instances:  2888\n",
            "Number of test instances:  2887\n",
            "Total number of instances: 28874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRS33g20HD5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_test_model_4 = NBAPredictionLSTM(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).cuda()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_INDEX) # ignore padding labels when calculating loss\n",
        "optimizer = torch.optim.Adam(seq_test_model_4.parameters(), lr=LEARNING_RATE)\n",
        "seq_test_model_4.init_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITVkDLvjHEFH",
        "colab_type": "code",
        "outputId": "81a64e4a-92a9-41aa-fe73-3767532df3e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "seq_train_loss_4, seq_train_acc_4, seq_val_acc_4 = train_model(seq_test_model_4, 10, 'NBA-LSTM-Seq-V4.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model over the validation set before training: 11.74%\n",
            "Epoch 01 Summary:\n",
            "\t\tTrain Loss: 0.995 | Train Acc: 57.60%\n",
            "\t\tVal. Acc: 56.52%\n",
            "Epoch 02 Summary:\n",
            "\t\tTrain Loss: 0.974 | Train Acc: 57.83%\n",
            "\t\tVal. Acc: 56.75%\n",
            "Epoch 03 Summary:\n",
            "\t\tTrain Loss: 0.969 | Train Acc: 57.88%\n",
            "\t\tVal. Acc: 56.76%\n",
            "Epoch 04 Summary:\n",
            "\t\tTrain Loss: 0.967 | Train Acc: 57.89%\n",
            "\t\tVal. Acc: 56.84%\n",
            "Epoch 05 Summary:\n",
            "\t\tTrain Loss: 0.965 | Train Acc: 57.95%\n",
            "\t\tVal. Acc: 56.85%\n",
            "Epoch 06 Summary:\n",
            "\t\tTrain Loss: 0.963 | Train Acc: 57.96%\n",
            "\t\tVal. Acc: 56.91%\n",
            "Epoch 07 Summary:\n",
            "\t\tTrain Loss: 0.962 | Train Acc: 57.95%\n",
            "\t\tVal. Acc: 56.95%\n",
            "Epoch 08 Summary:\n",
            "\t\tTrain Loss: 0.962 | Train Acc: 57.93%\n",
            "\t\tVal. Acc: 56.90%\n",
            "Epoch 09 Summary:\n",
            "\t\tTrain Loss: 0.961 | Train Acc: 58.02%\n",
            "\t\tVal. Acc: 56.91%\n",
            "Epoch 10 Summary:\n",
            "\t\tTrain Loss: 0.961 | Train Acc: 58.03%\n",
            "\t\tVal. Acc: 56.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbE2t1cgHEPC",
        "colab_type": "code",
        "outputId": "415fef73-0df5-49cf-dd7d-89e0d1109c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Print Model's accuracy over Test Set\n",
        "seq_test_acc_4 = accuracy(seq_test_model_4, test_loader)\n",
        "print(f\"This model's accuracy over the Test set: {seq_test_acc_4:.4}%\")\n",
        "print(f\"This model's accuracy over the Train set: {seq_train_acc_4:.4}%\")\n",
        "print(f\"This model's accuracy over the Validation set: {seq_val_acc_4:.4}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This model's accuracy over the Test set: 57.18%\n",
            "This model's accuracy over the Train set: 58.03%\n",
            "This model's accuracy over the Validation set: 56.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxkRSk23JZGz",
        "colab_type": "text"
      },
      "source": [
        "**Sequnce Length = 32**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3J9tjY0Jcdk",
        "colab_type": "code",
        "outputId": "409794d6-b76d-49a9-aad5-ed8916280dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "data_sequences, data_scores = pre_process_data(stats.values(), 32)\n",
        "data_labels = binning(data_scores)\n",
        "\n",
        "train_loader, val_loader, test_loader = divide_dataset(data_sequences, data_labels, BATCH_SIZE, TRAIN_PORTION, VALIDATION_PORTION)\n",
        "\n",
        "print(f'Number of train instances:  {len(train_loader.dataset)}')\n",
        "print(f'Number of validation instances:  {len(val_loader.dataset)}')\n",
        "print(f'Number of test instances:  {len(test_loader.dataset)}')\n",
        "print(f'Total number of instances: {data_sequences.shape[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train instances:  11900\n",
            "Number of validation instances:  1488\n",
            "Number of test instances:  1488\n",
            "Total number of instances: 14876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UsTH4A6JcwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_test_model_5 = NBAPredictionLSTM(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).cuda()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_INDEX) # ignore padding labels when calculating loss\n",
        "optimizer = torch.optim.Adam(seq_test_model_5.parameters(), lr=LEARNING_RATE)\n",
        "seq_test_model_5.init_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9RulZZGJc24",
        "colab_type": "code",
        "outputId": "e6052e3b-dcf2-4722-bc84-36aacb7d2e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "seq_train_loss_5, seq_train_acc_5, seq_val_acc_5 = train_model(seq_test_model_5, 10, 'NBA-LSTM-Seq-V4.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model over the validation set before training: 10.7%\n",
            "Epoch 01 Summary:\n",
            "\t\tTrain Loss: 0.990 | Train Acc: 56.34%\n",
            "\t\tVal. Acc: 55.15%\n",
            "Epoch 02 Summary:\n",
            "\t\tTrain Loss: 0.966 | Train Acc: 56.41%\n",
            "\t\tVal. Acc: 55.18%\n",
            "Epoch 03 Summary:\n",
            "\t\tTrain Loss: 0.960 | Train Acc: 56.42%\n",
            "\t\tVal. Acc: 55.20%\n",
            "Epoch 04 Summary:\n",
            "\t\tTrain Loss: 0.958 | Train Acc: 56.47%\n",
            "\t\tVal. Acc: 55.30%\n",
            "Epoch 05 Summary:\n",
            "\t\tTrain Loss: 0.956 | Train Acc: 56.50%\n",
            "\t\tVal. Acc: 55.22%\n",
            "Epoch 06 Summary:\n",
            "\t\tTrain Loss: 0.954 | Train Acc: 56.51%\n",
            "\t\tVal. Acc: 55.25%\n",
            "Epoch 07 Summary:\n",
            "\t\tTrain Loss: 0.953 | Train Acc: 56.50%\n",
            "\t\tVal. Acc: 55.29%\n",
            "Epoch 08 Summary:\n",
            "\t\tTrain Loss: 0.953 | Train Acc: 56.54%\n",
            "\t\tVal. Acc: 55.32%\n",
            "Epoch 09 Summary:\n",
            "\t\tTrain Loss: 0.952 | Train Acc: 56.52%\n",
            "\t\tVal. Acc: 55.21%\n",
            "Epoch 10 Summary:\n",
            "\t\tTrain Loss: 0.951 | Train Acc: 56.61%\n",
            "\t\tVal. Acc: 55.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR9xQbKfJc7z",
        "colab_type": "code",
        "outputId": "a1cd7f00-430d-430b-cc5e-0ddfe49f1a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Print Model's accuracy over Test Set\n",
        "seq_test_acc_5 = accuracy(seq_test_model_5, test_loader)\n",
        "print(f\"This model's accuracy over the Test set: {seq_test_acc_5:.4}%\")\n",
        "print(f\"This model's accuracy over the Train set: {seq_train_acc_5:.4}%\")\n",
        "print(f\"This model's accuracy over the Validation set: {seq_val_acc_5:.4}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This model's accuracy over the Test set: 57.31%\n",
            "This model's accuracy over the Train set: 56.61%\n",
            "This model's accuracy over the Validation set: 55.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DjGm97bWoIB",
        "colab_type": "text"
      },
      "source": [
        "**Experiment #3**\n",
        "\n",
        "We now want to check if a regular Feed Forward Network performs better on the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-swXVJHXOl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FFNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(FFNN, self).__init__()\n",
        "        \n",
        "        #TODO: Initialize parameters.\n",
        "        self.fc1 = nn.Linear(input_size,128)\n",
        "        self.fc2 = nn.Linear(128,64)\n",
        "        self.fc3 = nn.Linear(64,output_size)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.xavier_uniform_(self.fc3.weight)\n",
        "\n",
        "    def forward(self, X):\n",
        "        #TODO: Implement forward computation.\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.relu(self.fc2(X))\n",
        "        X = self.fc3(X)\n",
        "        \n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGxuZ4ZyfiAX",
        "colab_type": "code",
        "outputId": "9d77d2f7-8ccf-4573-930c-705c63aec265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "ff_data = data_sequences.reshape(-1, 27)\n",
        "ff_labels = data_labels.reshape(-1)\n",
        "\n",
        "print(ff_data.shape)\n",
        "print(ff_labels.shape)\n",
        "\n",
        "train_loader, val_loader, test_loader = divide_dataset(ff_data, ff_labels, batch_size=64)\n",
        "\n",
        "print(f'Number of train instances:  {len(train_loader.dataset)}')\n",
        "print(f'Number of validation instances:  {len(val_loader.dataset)}')\n",
        "print(f'Number of test instances:  {len(test_loader.dataset)}')\n",
        "print(f'Total number of instances: {ff_data.shape[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(476032, 27)\n",
            "(476032,)\n",
            "Number of train instances:  380825\n",
            "Number of validation instances:  47604\n",
            "Number of test instances:  47603\n",
            "Total number of instances: 476032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy5QwKcQgveU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD_INDEX = 5\n",
        "INPUT_DIM = 27\n",
        "OUTPUT_DIM = 5\n",
        "LEARNING_RATE=0.005\n",
        "\n",
        "ff_model = FFNN(INPUT_DIM, OUTPUT_DIM).cuda()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_INDEX) # ignore padding labels when calculating loss\n",
        "optimizer = torch.optim.Adam(ff_model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlYhBHzOiS5F",
        "colab_type": "code",
        "outputId": "d3dbfad3-9496-4541-9cef-390c32814220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "ff_train_loss, ff_train_acc, ff_val_acc = train_model(ff_model, 10, 'NBA-LSTM-Seq-V4.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model over the validation set before training: 11.65%\n",
            "Epoch 01 Summary:\n",
            "\t\tTrain Loss: 1.021 | Train Acc: 50.76%\n",
            "\t\tVal. Acc: 49.37%\n",
            "Epoch 02 Summary:\n",
            "\t\tTrain Loss: 0.996 | Train Acc: 52.43%\n",
            "\t\tVal. Acc: 50.81%\n",
            "Epoch 03 Summary:\n",
            "\t\tTrain Loss: 0.991 | Train Acc: 52.22%\n",
            "\t\tVal. Acc: 50.99%\n",
            "Epoch 04 Summary:\n",
            "\t\tTrain Loss: 0.992 | Train Acc: 52.47%\n",
            "\t\tVal. Acc: 51.10%\n",
            "Epoch 05 Summary:\n",
            "\t\tTrain Loss: 0.990 | Train Acc: 52.89%\n",
            "\t\tVal. Acc: 51.59%\n",
            "Epoch 06 Summary:\n",
            "\t\tTrain Loss: 0.989 | Train Acc: 54.59%\n",
            "\t\tVal. Acc: 53.43%\n",
            "Epoch 07 Summary:\n",
            "\t\tTrain Loss: 0.992 | Train Acc: 54.02%\n",
            "\t\tVal. Acc: 52.72%\n",
            "Epoch 08 Summary:\n",
            "\t\tTrain Loss: 0.990 | Train Acc: 52.77%\n",
            "\t\tVal. Acc: 51.39%\n",
            "Epoch 09 Summary:\n",
            "\t\tTrain Loss: 0.990 | Train Acc: 53.60%\n",
            "\t\tVal. Acc: 52.32%\n",
            "Epoch 10 Summary:\n",
            "\t\tTrain Loss: 0.989 | Train Acc: 52.98%\n",
            "\t\tVal. Acc: 51.76%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hsuew-fiyqJ",
        "colab_type": "code",
        "outputId": "5140ac07-5067-4eeb-e25b-75e289a07c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Print Model's accuracy measures\n",
        "ff_test_acc = accuracy(ff_model, test_loader)\n",
        "print(f\"This model's accuracy over the Test set: {ff_test_acc:.4}%\")\n",
        "print(f\"This model's accuracy over the Train set: {ff_train_acc:.4}%\")\n",
        "print(f\"This model's accuracy over the Validation set: {ff_val_acc:.4}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This model's accuracy over the Test set: 53.97%\n",
            "This model's accuracy over the Train set: 52.98%\n",
            "This model's accuracy over the Validation set: 51.76%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ResKeU1Wf2Pi",
        "colab_type": "text"
      },
      "source": [
        "# **Conclusion**\n",
        "\n",
        "After running several experiments it is quite clear that our approach is beneficial.\n",
        "\n",
        "When we divide the data into sequences and run them through a sequential model, the results we get are better than the results a simple Feed Forward model was able to achieve:\n",
        "\n",
        "**LSTM Model with sequnce length = 4**:\n",
        "  * Test Accuracy = 59.85%\n",
        "  * Train Accuracy = 58.49%\n",
        "  * Validation Accuracy = 57.46%\n",
        "\n",
        "\n",
        "**Feed Forward Model with 3 Fully Connected Layers**:\n",
        "  * Test Accuracy: 53.97%\n",
        "  * Train Accuracy: 52.98%\n",
        "  * Validation Accuracy: 51.76%\n",
        "\n"
      ]
    }
  ]
}